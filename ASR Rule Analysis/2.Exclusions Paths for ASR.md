### Getting Exclusions from KQL for Intune for ASR with "Risk" Lables

This KQL  analyzes Attack Surface Reduction activity on a "specific" device (add in line 2) and shows which files triggered the ASR events, how often they occurred, 
and which ASR rules were involved. It identifies the exact file path that caused the rule to fire and determines the best exclusion path to consider if the file is legitimate.
It also applies a risk label so analysts can easily understand whether an exclusion would be safe or potentially harmful. A SOC team can use the output to decide which
ASR events are false positives during audit or testing, and then use the identified exclusion paths to create precise and minimal ASR exclusions in Intune so that
business required applications continue functioning without weakening security.

```
//Get exclusion paths
let TargetDevice = "XXXXXX"; //Insert DeviceName Here
let TimeRange = 90d;
DeviceEvents
| where Timestamp > ago(TimeRange)
| where DeviceName == TargetDevice
| where ActionType startswith "Asr"
| extend AF = tostring(AdditionalFields)
| extend RuleGUID = coalesce(
    extract(@'"RuleId"\s*:\s*"([0-9A-Fa-f-]{36})"', 1, AF),
    extract(@'"ruleId"\s*:\s*"([0-9A-Fa-f-]{36})"', 1, AF),
    extract(@'"RuleID"\s*:\s*"([0-9A-Fa-f-]{36})"', 1, AF),
    extract(@'"ruleID"\s*:\s*"([0-9A-Fa-f-]{36})"', 1, AF)
)
| extend EvaluatedPath = coalesce(
    extract(@'"Path"\s*:\s*"([^"]+)"', 1, AF),
    extract(@'"path"\s*:\s*"([^"]+)"', 1, AF)
)
| extend ChildFullPath = iif(isnotempty(FolderPath) and isnotempty(FileName), strcat(FolderPath, "\\", FileName), FolderPath)
| extend PreferredExclusionPath = coalesce(EvaluatedPath, ChildFullPath)
| extend FileThatTriggeredASR = coalesce(ChildFullPath, FolderPath)
// Risk classification for exclusion candidates
| extend P = tolower(PreferredExclusionPath)
| extend RiskFlag = case(
    isempty(PreferredExclusionPath), "UNKNOWN - No path captured",
    P startswith "c:\\windows\\system32\\" or P startswith "c:\\windows\\syswow64\\", "HIGH - Windows system binary (avoid excluding)",
    P has "\\program files\\" and P has "\\microsoft office\\", "MED - Microsoft Office binary (avoid unless confirmed needed)",
    P has "\\program files\\", "MED - Program Files binary (validate signer/publisher)",
    P startswith "c:\\programdata\\", "MED - ProgramData (shared, validate ownership)",
    P has "\\users\\" and (P has "\\appdata\\" or P has "\\inetcache\\" or P has "\\temp\\"), "HIGH - User-writable temp/cache (risky exclusion)",
    P has "\\onedrive", "MED/HIGH - OneDrive user content (risky, scope narrowly)",
    P startswith "c:\\users\\", "MED/HIGH - User profile path (scope narrowly)",
    "UNKNOWN - Review required"
)
| summarize EventCount = count(), arg_max(Timestamp, InitiatingProcessFolderPath, InitiatingProcessCommandLine, FolderPath, ChildFullPath, ProcessCommandLine, AdditionalFields, FileThatTriggeredASR) by DeviceName, ActionType, RuleGUID, InitiatingProcessFileName, FileName, PreferredExclusionPath, RiskFlag
| project Timestamp, DeviceName, ActionType, RuleGUID, RiskFlag, EventCount, InitiatingProcessFileName, InitiatingProcessFolderPath, InitiatingProcessCommandLine, FileName, FolderPath, ChildFullPath, FileThatTriggeredASR, ProcessCommandLine, PreferredExclusionPath, AdditionalFields
| order by EventCount desc, Timestamp desc
```
### The story behind this event

What we’re looking at is a normal Office workflow that Defender’s Attack Surface Reduction rules are designed to watch closely, because attackers often use Office as the 
first step to run code. In this record, the initiating process is powerpnt.exe, meaning PowerPoint is the application that started the chain of activity. The initiating process
path shows it’s the standard Microsoft Office install location, which tells us the parent process itself is legitimate Office. In other words, the user opened something in 
PowerPoint, and PowerPoint then attempted an action that matched an ASR rule’s “blocked behavior.” ASR rules are built to stop behaviors that are commonly abused by
malware, especially when Office tries to create or run executable content or trigger suspicious execution patterns.

Now look at the “file that got blocked” side of the record. The output shows FolderPath as C:\Program Files (x86)\Microsoft Office\Office15 and the file name is a DLL called 
AntiMalware.Utils.RemoteAPI.Interop-...dll, which the query builds into the full file path in ChildFullPath and also surfaces as FileThatTriggeredASR. That means the 
ASR event was applied to that specific DLL at that specific path. In the Defender hunting schema, FileName is the name of the file the action was applied to, and FolderPath
is the folder containing that file, so that combination is the authoritative “target file” for this event.

<img width="3063" height="1711" alt="image" src="https://github.com/user-attachments/assets/58bc6411-a7e4-4f65-ab0c-8677043589e6" />

### Exclusions

If you absolutely must exclude this, follow these guidelines:

- Do not exclude the entire folder  
- Do not exclude PowerPoint (powerpnt.exe)  
- Do not use wildcards such as *.dll or Office15* directories  

Use a single, file‑level exclusion only:

C:\Program Files (x86)\Microsoft Office\Office15\AntiMalware.Utils.RemoteAPI.Interop-*.dll

or the strict GUID-length pattern:

C:\Program Files (x86)\Microsoft Office\Office15\AntiMalware.Utils.RemoteAPI.Interop-GUID.dll

### Risk Labels

Risk labels in this query help you quickly judge whether an ASR exclusion is safe or dangerous by categorizing the path that triggered the rule, because ASR rules are designed to block behaviors attackers commonly abuse and broad exclusions can reopen those attack paths.

HIGH – Windows system binary (avoid excluding)  
Examples:  
- C:\Windows\System32\wscript.exe  
- C:\Windows\System32\cmd.exe  
These are common “living off the land” tools that attackers leverage, so excluding them weakens core protections.

MED – Microsoft Office binary (avoid unless confirmed needed)  
Examples:  
- C:\Program Files\Microsoft Office\root\Office16\winword.exe  
- Office add-in DLLs  
Broad Office exclusions undermine rules meant to prevent Office-driven attack chains.

MED – Program Files binary (validate signer/publisher)  
Example:  
- C:\Program Files\Vendor\App\app.exe  
Typically safer because it’s not user writable but still requires validation to ensure it’s legitimate and signed.

MED – ProgramData (shared, validate ownership)  
Example:  
- C:\ProgramData\AppCache\tool.exe  
This directory can be abused because multiple processes can write there.

HIGH – User-writable temp/cache (risky exclusion)  
Examples:  
- C:\Users\Elliot\AppData\Local\Temp\payload.exe  
- C:\Users\Elliot\AppData\Local\Microsoft\Windows\INetCache\file.exe  
These are high-risk because attackers commonly stage payloads in writable directories.

MED/HIGH – OneDrive user content (risky, scope narrowly)  
Example:  
- C:\Users\Elliot\OneDrive\Scripts\tool.exe  
Content here is user controlled and externally synced.

MED/HIGH – User profile path (scope narrowly)  
Example:  
- C:\Users\Elliot\Downloads\installer.exe  
This is also attacker friendly.

UNKNOWN – Review required / No path captured  
This means telemetry didn’t include enough detail to determine whether an exclusion is safe and requires reviewing the raw event.

Using these labels, analysts can decide whether to allow a single file, tune a configuration issue, or avoid an exclusion entirely, keeping ASR protections effective while minimizing business impact.

<img width="2983" height="1547" alt="image" src="https://github.com/user-attachments/assets/8a701149-b0fc-4790-80f4-98e5c69ca057" />


### Next Step: Apply Exclusions

Now that you’ve identified valid initiating executables and exclusion paths using telemetry, move on to application guidance and validation best practices in [Applying Exclusions for ASR](3.%20Applying%20Exclusions%20for%20ASR.md). Use that as a checklist for implementation and review.


